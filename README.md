# fact-law-classifier
Code for https://huggingface.co/ss108/legal-citation-bert

Legal Citation BERT is a version of `dslim/bert-base-NER` trained to recognize
American legal citations. 

Some of the training text was generated by LLMs, but the substantial majority
consists of docket entries from Courtlistener, which I got from Pile-of-Law's
dataset(https://huggingface.co/datasets/pile-of-law/pile-of-law). 

The subset of the Pile-of-Law CL Docket Entries dataset that was used consists
of approximately the first 50 documents. Since the entire corpus of raw data is
small enough to fit in GitHub atm, precisely which Courtlistener documents were
used can be gleaned from the file names in `raw_data`

Credits:
@misc{hendersonkrass2022pileoflaw,
  url = {https://arxiv.org/abs/2207.00220},
  author = {Henderson*, Peter and Krass*, Mark S. and Zheng, Lucia and Guha, Neel and Manning, Christopher D. and Jurafsky, Dan and Ho, Daniel E.},
  title = {Pile of Law: Learning Responsible Data Filtering from the Law and a 256GB Open-Source Legal Dataset},
  publisher = {arXiv},
  year = {2022}
}

